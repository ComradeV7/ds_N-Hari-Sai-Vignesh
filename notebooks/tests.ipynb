{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1VFkOxRM5TeNg9hT-SScuVswyXHli8Xft","authorship_tag":"ABX9TyMsMElzEL5v47HfLnJg7sRX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Concurrent ANOVA Test"],"metadata":{"id":"rZeKAleQ-Kz6"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"3Ow97Mg31znP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761236351658,"user_tz":-330,"elapsed":1999,"user":{"displayName":"Vignesh","userId":"01236765758149599503"}},"outputId":"eb50e031-3916-415d-8169-cdc768e44631"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Found 5 sentiment groups to compare: ['Fear' 'Neutral' 'Greed' 'Extreme Greed' 'Extreme Fear']\n","\n","Test 1: total_pnl_usd -\n","  F-Statistic: 1.2370\n","  P-Value: 0.2978\n","  Result: NOT SIGNIFICANT. We cannot conclude the average PnL is\n","  different between the sentiment groups.\n","\n","Test 2: total_volume_usd -\n","  F-Statistic: 1.9933\n","  P-Value: 0.0985\n","  Result: NOT SIGNIFICANT. We cannot conclude the average Volume is\n","  different between the sentiment groups.\n","\n","Test 3: pnl_volatility -\n","  F-Statistic: 0.6685\n","  P-Value: 0.6148\n","  Result: NOT SIGNIFICANT. We cannot conclude the average PnL Volatility is\n","  different between the sentiment groups.\n"]}],"source":["import pandas as pd\n","import scipy.stats as stats\n","from statsmodels.stats.multicomp import pairwise_tukeyhsd\n","import os\n","\n","output_dir = '/content/drive/MyDrive/Projects/ds_N-Hari-Sai-Vignesh/outputs'\n","\n","def run_anova_tests(file_path='merged_daily_data.csv'):\n","    \"\"\"\n","    Performs ANOVA tests to check for significant differences in trading\n","    metrics across different market sentiment classifications.\n","    \"\"\"\n","\n","    try:\n","\n","        df = pd.read_csv(file_path, parse_dates=['date'], index_col='date')\n","\n","\n","        unique_sentiments = df['classification'].unique()\n","        print(f\"\\nFound {len(unique_sentiments)} sentiment groups to compare: {unique_sentiments}\")\n","\n","        # Test 1: Total PnL (total_pnl_usd)\n","        print(\"\\nTest 1: total_pnl_usd -\")\n","        pnl_groups = [df[df['classification'] == sentiment]['total_pnl_usd'] for sentiment in unique_sentiments]\n","\n","        # Run the ANOVA test\n","        f_statistic_pnl, p_value_pnl = stats.f_oneway(*pnl_groups)\n","\n","        print(f\"  F-Statistic: {f_statistic_pnl:.4f}\")\n","        print(f\"  P-Value: {p_value_pnl:.4f}\")\n","\n","        # Results\n","        if p_value_pnl < 0.05:\n","            print(\"  Result: SIGNIFICANT. The average PnL is statistically different\")\n","            print(\"  between at least two of the sentiment groups.\")\n","        else:\n","            print(\"  Result: NOT SIGNIFICANT. We cannot conclude the average PnL is\")\n","            print(\"  different between the sentiment groups.\")\n","\n","\n","        # Test 2: Total Volume (total_volume_usd)\n","        print(\"\\nTest 2: total_volume_usd -\")\n","        volume_groups = [df[df['classification'] == sentiment]['total_volume_usd'] for sentiment in unique_sentiments]\n","\n","        # Run the ANOVA test\n","        f_statistic_vol, p_value_vol = stats.f_oneway(*volume_groups)\n","\n","        print(f\"  F-Statistic: {f_statistic_vol:.4f}\")\n","        print(f\"  P-Value: {p_value_vol:.4f}\")\n","\n","        # Results\n","        if p_value_vol < 0.05:\n","            print(\"  Result: SIGNIFICANT. The average Volume is statistically different\")\n","            print(\"  between at least two of the sentiment groups.\")\n","        else:\n","            print(\"  Result: NOT SIGNIFICANT. We cannot conclude the average Volume is\")\n","            print(\"  different between the sentiment groups.\")\n","\n","\n","        # Test 3: PnL Volatility (pnl_volatility)\n","        print(\"\\nTest 3: pnl_volatility -\")\n","        volatility_groups = [df[df['classification'] == sentiment]['pnl_volatility'] for sentiment in unique_sentiments]\n","\n","        # Run the ANOVA test\n","        f_statistic_vola, p_value_vola = stats.f_oneway(*volatility_groups)\n","\n","        print(f\"  F-Statistic: {f_statistic_vola:.4f}\")\n","        print(f\"  P-Value: {p_value_vola:.4f}\")\n","\n","        # Results\n","        if p_value_vola < 0.05:\n","            print(\"  Result: SIGNIFICANT. The average PnL Volatility is statistically different\")\n","            print(\"  between at least two of the sentiment groups.\")\n","        else:\n","            print(\"  Result: NOT SIGNIFICANT. We cannot conclude the average PnL Volatility is\")\n","            print(\"  different between the sentiment groups.\")\n","\n","        # Post-Hoc Test (Tukey's HSD)\n","        # This is only useful if an ANOVA test was significant.\n","        # It tells us *which specific groups* are different from each other.\n","\n","        if p_value_pnl < 0.05:\n","            print(\"\\nPost-Hoc Test for total_pnl_usd (Tukey's HSD) - \")\n","            print(\"This test shows which specific pairs are different:\\n\")\n","            tukey_results = pairwise_tukeyhsd(endog=df['total_pnl_usd'],\n","                                              groups=df['classification'],\n","                                              alpha=0.05)\n","            print(tukey_results)\n","\n","            # Save results to a file\n","            os.makedirs(output_dir, exist_ok=True)\n","            with open(f\"{output_dir}/tukey_pnl_results.txt\", \"w\") as f:\n","                f.write(str(tukey_results))\n","\n","    except FileNotFoundError:\n","        print(f\"Error: The file '{file_path}' was not found.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","# Run the analysis\n","run_anova_tests('/content/drive/MyDrive/Projects/ds_N-Hari-Sai-Vignesh/csv_files/merged_daily_data.csv')"]},{"cell_type":"code","source":["data = '/content/drive/MyDrive/Projects/ds_N-Hari-Sai-Vignesh/csv_files/merged_daily_data.csv'"],"metadata":{"id":"ixjprN3a6ALo","executionInfo":{"status":"ok","timestamp":1761237023623,"user_tz":-330,"elapsed":40,"user":{"displayName":"Vignesh","userId":"01236765758149599503"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Lagged ANOVA Test"],"metadata":{"id":"YE7QwBLd-SOQ"}},{"cell_type":"code","source":["import pandas as pd\n","import scipy.stats as stats\n","import os\n","\n","def perform_lagged_anova(file_path='merged_daily_data.csv'):\n","    \"\"\"\n","    Performs lag analysis (ANOVA) to see if yesterday's sentiment\n","    predicts today's trading behavior (PnL and Volume).\n","    \"\"\"\n","    try:\n","\n","        df = pd.read_csv(file_path, parse_dates=['date'], index_col='date')\n","        df.sort_index(inplace=True)\n","\n","        # Create Lagged Feature\n","        # Create a 1-day lag for both the numeric value and the classification\n","        df['value_lag_1'] = df['value'].shift(1)\n","        df['classification_lag_1'] = df['classification'].shift(1)\n","\n","        # Clean Data\n","        # Lagging introduces NaN values for the first row\n","        original_rows = df.shape[0]\n","        df.dropna(subset=['classification_lag_1', 'value_lag_1'], inplace=True)\n","        print(f\"Dropped {original_rows - df.shape[0]} row with NaN values after lagging.\")\n","\n","        if df.empty:\n","            print(\"Error: No data left after dropping NaNs.\")\n","            return\n","\n","        # Run ANOVA on Lagged Classification\n","        # Get unique classifications for the lagged data\n","        unique_sentiments_lag1 = df['classification_lag_1'].unique()\n","\n","        if len(unique_sentiments_lag1) < 2:\n","            print(\"Skipping ANOVA for lag 1: Not enough unique sentiment groups.\")\n","            return\n","\n","        print(f\"Comparing {len(unique_sentiments_lag1)} groups from yesterday's sentiment: {unique_sentiments_lag1}\")\n","\n","        # Test 1: Yesterday's Sentiment vs. Today's PnL\n","        print(\"\\nTest: classification_lag_1 vs. total_pnl_usd\")\n","        pnl_groups_lag1 = [df[df['classification_lag_1'] == sentiment]['total_pnl_usd']\n","                           for sentiment in unique_sentiments_lag1]\n","\n","        # Run the ANOVA test for PnL\n","        f_stat_pnl_lag1, p_value_pnl_lag1 = stats.f_oneway(*pnl_groups_lag1)\n","\n","        print(f\"  F-Statistic: {f_stat_pnl_lag1:.4f}\")\n","        print(f\"  P-Value: {p_value_pnl_lag1:.4f}\")\n","\n","        if p_value_pnl_lag1 < 0.05:\n","            print(\"  Result: SIGNIFICANT! Yesterday's sentiment has a statistical\")\n","            print(\"  relationship with today's total PnL.\")\n","        else:\n","            print(\"  Result: NOT SIGNIFICANT. Yesterday's sentiment does not\")\n","            print(\"  statistically predict today's total PnL.\")\n","\n","        # Test 2: Yesterday's Sentiment vs. Today's Volume\n","        print(\"\\nTest: classification_lag_1 vs. total_volume_usd\")\n","        vol_groups_lag1 = [df[df['classification_lag_1'] == sentiment]['total_volume_usd']\n","                           for sentiment in unique_sentiments_lag1]\n","\n","        # Run the ANOVA test for Volume\n","        f_stat_vol_lag1, p_value_vol_lag1 = stats.f_oneway(*vol_groups_lag1)\n","\n","        print(f\"  F-Statistic: {f_stat_vol_lag1:.4f}\")\n","        print(f\"  P-Value: {p_value_vol_lag1:.4f}\")\n","\n","        if p_value_vol_lag1 < 0.05:\n","            print(\"  Result: SIGNIFICANT! Yesterday's sentiment has a statistical\")\n","            print(\"  relationship with today's total volume.\")\n","        else:\n","            print(\"  Result: NOT SIGNIFICANT. Yesterday's sentiment does not\")\n","            print(\"  statistically predict today's total volume.\")\n","\n","    except FileNotFoundError:\n","        print(f\"Error: The file '{file_path}' was not found.\")\n","        print(\"Please make sure 'merged_daily_data.csv' is in the same folder.\")\n","    except ImportError:\n","        print(\"Error: Required library not found.\")\n","        print(\"Please run: pip install pandas scipy\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","# Run the lag analysis\n","perform_lagged_anova(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nuDzJkR7V0Y","executionInfo":{"status":"ok","timestamp":1761237614252,"user_tz":-330,"elapsed":51,"user":{"displayName":"Vignesh","userId":"01236765758149599503"}},"outputId":"03301c56-a18e-4749-8082-983558eb5800"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Dropped 1 row with NaN values after lagging.\n","Comparing 5 groups from yesterday's sentiment: ['Fear' 'Neutral' 'Greed' 'Extreme Greed' 'Extreme Fear']\n","\n","Test: classification_lag_1 vs. total_pnl_usd\n","  F-Statistic: 0.9636\n","  P-Value: 0.4294\n","  Result: NOT SIGNIFICANT. Yesterday's sentiment does not\n","  statistically predict today's total PnL.\n","\n","Test: classification_lag_1 vs. total_volume_usd\n","  F-Statistic: 3.0853\n","  P-Value: 0.0179\n","  Result: SIGNIFICANT! Yesterday's sentiment has a statistical\n","  relationship with today's total volume.\n"]}]},{"cell_type":"markdown","source":["Tukey's HSD Post-Hoc Test"],"metadata":{"id":"J4MsNfuZ-WNo"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def run_tukey_posthoc_test(file_path='merged_daily_data.csv'):\n","    \"\"\"\n","    Performs a Tukey's HSD post-hoc test to identify which specific\n","    lagged sentiment groups have a significant effect on today's total volume.\n","    \"\"\"\n","    try:\n","        df = pd.read_csv(file_path, parse_dates=['date'], index_col='date')\n","\n","        df.sort_index(inplace=True)\n","\n","        # Create the 1-day lagged classification feature\n","        df['classification_lag_1'] = df['classification'].shift(1)\n","        df.dropna(subset=['classification_lag_1'], inplace=True)\n","\n","        # Tukey's HSD Test\n","        # This is the core statistical test\n","        tukey_results = pairwise_tukeyhsd(\n","            endog=df['total_volume_usd'],\n","            groups=df['classification_lag_1'],\n","            alpha=0.05\n","        )\n","\n","        print(\"\\n--- Tukey's HSD Test Results ---\")\n","        print(tukey_results)\n","\n","        # Save Test Results\n","        results_path = f\"{output_dir}/tukey_volume_lag1_results.txt\"\n","\n","        with open(results_path, \"w\") as f:\n","            f.write(\"Tukey's HSD Post-Hoc Test Results\\n\")\n","            f.write(\"Variable: total_volume_usd\\n\")\n","            f.write(\"Group: classification_lag_1 (Yesterday's Sentiment)\\n\\n\")\n","            f.write(str(tukey_results))\n","\n","        # Visualize the Difference\n","\n","        # Get the logical order of sentiments for plotting\n","        all_possible_sentiments = ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']\n","        unique_classifications = df['classification_lag_1'].unique()\n","        sentiment_order = [s for s in all_possible_sentiments if s in unique_classifications]\n","\n","        plt.figure(figsize=(12, 7))\n","        sns.boxplot(\n","            data=df,\n","            x='classification_lag_1',\n","            y='total_volume_usd',\n","            order=sentiment_order\n","        )\n","        plt.title(\"Today's Total Volume vs. Yesterday's Sentiment\")\n","        plt.xlabel(\"Yesterday's Sentiment Classification\")\n","        plt.ylabel(\"Today's Total Volume (USD)\")\n","        plt.tight_layout()\n","\n","        #Save the results\n","        plot_path = f\"{output_dir}/12_volume_by_lagged_sentiment_boxplot.png\"\n","        plt.savefig(plot_path)\n","        plt.clf()\n","        plt.close()\n","\n","    except FileNotFoundError:\n","        print(f\"Error: The file '{file_path}' was not found.\")\n","        print(\"Please make sure 'merged_daily_data.csv' is in the same folder.\")\n","    except ImportError:\n","        print(\"Error: Required library not found.\")\n","        print(\"Please run: pip install pandas statsmodels matplotlib seaborn\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","# Run the post-hoc test\n","run_tukey_posthoc_test(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhdHc0jm5Adu","executionInfo":{"status":"ok","timestamp":1761237033417,"user_tz":-330,"elapsed":1439,"user":{"displayName":"Vignesh","userId":"01236765758149599503"}},"outputId":"83883473-67ea-45ff-8e05-ec7ea2268f92"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Tukey's HSD Test Results ---\n","               Multiple Comparison of Means - Tukey HSD, FWER=0.05                \n","==================================================================================\n","    group1        group2       meandiff   p-adj      lower        upper     reject\n","----------------------------------------------------------------------------------\n"," Extreme Fear Extreme Greed -3774591.3107 0.0217 -7179866.2682 -369316.3532   True\n"," Extreme Fear          Fear -2362042.5331 0.3225 -5797373.4569 1073288.3908  False\n"," Extreme Fear         Greed -3265800.5631 0.0602 -6618340.2623    86739.136  False\n"," Extreme Fear       Neutral -3349646.1713  0.106 -7112862.6503  413570.3076  False\n","Extreme Greed          Fear  1412548.7777 0.1883  -366848.7918 3191946.3471  False\n","Extreme Greed         Greed   508790.7476 0.9072 -1104987.3005 2122568.7957  False\n","Extreme Greed       Neutral   424945.1394 0.9873 -1925917.5579 2775807.8367  False\n","         Fear         Greed  -903758.0301 0.5712 -2580027.8797  772511.8195  False\n","         Fear       Neutral  -987603.6383 0.7854 -3381795.8698 1406588.5933  False\n","        Greed       Neutral   -83845.6082    1.0 -2357648.6603  2189957.444  False\n","----------------------------------------------------------------------------------\n"]}]}]}